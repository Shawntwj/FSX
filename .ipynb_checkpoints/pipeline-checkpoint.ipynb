{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5914200",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02def98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>Its flagship product is captagon, an illegal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10872</th>\n",
       "      <td>The USTR did not say when the tariffs would ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5450</th>\n",
       "      <td>BASEL (BLOOMBERG) - Climate change threatens t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>SINGAPORE - The High Court has dismissed a den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13102</th>\n",
       "      <td>MOSCOW (REUTERS) - President Vladimir Putin sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9761</th>\n",
       "      <td>JAKARTA/SURABAYA (XINHUA, THE JAKARTA POST/ASI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>Washington's North Korea policy is becoming \"m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7330</th>\n",
       "      <td>MANILA - A typhoon that gathered devastating s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>A jump in fuel prices, a dip in port activity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9019</th>\n",
       "      <td>Amazon mollies are all female, and they produc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         content summary\n",
       "12785  Its flagship product is captagon, an illegal, ...\n",
       "10872  The USTR did not say when the tariffs would ta...\n",
       "5450   BASEL (BLOOMBERG) - Climate change threatens t...\n",
       "11284  SINGAPORE - The High Court has dismissed a den...\n",
       "13102  MOSCOW (REUTERS) - President Vladimir Putin sa...\n",
       "...                                                  ...\n",
       "9761   JAKARTA/SURABAYA (XINHUA, THE JAKARTA POST/ASI...\n",
       "8379   Washington's North Korea policy is becoming \"m...\n",
       "7330   MANILA - A typhoon that gathered devastating s...\n",
       "4383   A jump in fuel prices, a dip in port activity ...\n",
       "9019   Amazon mollies are all female, and they produc...\n",
       "\n",
       "[10980 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "cwd = os.path.abspath('./news Classifier/CSV Data for Classifier') \n",
    "files = os.listdir(cwd) \n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "        df = df.append(pd.read_csv(cwd+\"/\"+file), ignore_index=True) \n",
    "        \n",
    "df = df.dropna()\n",
    "df.columns\n",
    "X = df.drop(['Unnamed: 0', 'date', 'location', 'news title', 'news source(url)',\n",
    "       'keywords', 'class_name', 'new_class_name'], axis=1)\n",
    "\n",
    "y = df['new_class_name']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6abc4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the BaseEstimator\n",
    "import re \n",
    "from sklearn.base import BaseEstimator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# define the class FeatureEngineering\n",
    "# This will be our custom transformer that will create 3 new binary columns\n",
    "# custom transformer must have methods fit and transform\n",
    "class FeatureEngineering(BaseEstimator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, documents, y=None):\n",
    "        return self\n",
    "    \n",
    "        \n",
    "    def transform(self, x_dataset):\n",
    "        \"\"\"\n",
    "        Function: split text into words and return the root form of the words\n",
    "        Args:\n",
    "          text(str): the article\n",
    "        Return:\n",
    "          lem(list of str): a list of the root form of the article words\n",
    "        \"\"\"\n",
    "        def preprocess(text):\n",
    "\n",
    "            # Normalize text\n",
    "            text = re.sub(r\"[^a-zA-Z]\", \" \", str(text).lower())\n",
    "\n",
    "            # Tokenize text\n",
    "            token = word_tokenize(text)\n",
    "\n",
    "            # Remove stop words\n",
    "            stop = stopwords.words(\"english\")\n",
    "            new_stop_words_list = ['said', 'us', 'also', 'mr']\n",
    "            stop.extend(new_stop_words_list)\n",
    "            words = [t for t in token if t not in stop]\n",
    "\n",
    "            # Lemmatization\n",
    "            lem = [WordNetLemmatizer().lemmatize(w) for w in words]\n",
    "\n",
    "            return lem\n",
    "        \n",
    "        x_dataset.head()\n",
    "\n",
    "        x_dataset[\"Preprocessed_Text\"] = x_dataset['content summary'].apply(lambda x: preprocess(x))\n",
    "        x_dataset['Preprocessed_Text2'] = x_dataset['Preprocessed_Text'].apply(' '.join)\n",
    "        \n",
    "        \n",
    "        return x_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6159e186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-467e96f9d59d>:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_dataset[\"Preprocessed_Text\"] = x_dataset['content summary'].apply(lambda x: preprocess(x))\n",
      "<ipython-input-2-467e96f9d59d>:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x_dataset['Preprocessed_Text2'] = x_dataset['Preprocessed_Text'].apply(' '.join)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "\n",
    "preprocessor = Pipeline(steps=[('feature engineering', FeatureEngineering()), \n",
    "                               ('col_selector', ColumnSelector(cols=('Preprocessed_Text2'),drop_axis=True)),\n",
    "                               ('tfidf',TfidfVectorizer()),\n",
    "                            ])\n",
    "\n",
    "\n",
    "train_features = preprocessor.fit(X_train)\n",
    "test_features = preprocessor.fit(X_test)\n",
    "\n",
    "train_features = train_features.transform(X_train)\n",
    "test_features = test_features.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3972b5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x18643 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 597456 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39bc12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost \n",
    "from sklearn.metrics  import classification_report\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def fit_eval_model(cls_name,model, train_features, y_train, test_features, y_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function: train and evaluate a machine learning classifier.\n",
    "    Args:\n",
    "      model: machine learning classifier\n",
    "      train_features: train data extracted features\n",
    "      y_train: train data lables\n",
    "      test_features: train data extracted features\n",
    "      y_test: train data lables\n",
    "    Return:\n",
    "      results(dictionary): a dictionary of the model training time and classification report\n",
    "    \"\"\"\n",
    "    results ={}\n",
    "    \n",
    "    # Start time\n",
    "    start = time.time()\n",
    "    # Train the model\n",
    "    model.fit(train_features, y_train)\n",
    "    # End time\n",
    "    end = time.time()\n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end - start\n",
    "    \n",
    "    # Test the model\n",
    "    train_predicted = model.predict(train_features)\n",
    "    test_predicted = model.predict(test_features)\n",
    "    \n",
    "    # Save the model\n",
    "    filename = cls_name + '.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    # Classification report\n",
    "    results['classification_report'] = classification_report(y_test, test_predicted)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0965f53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shawn\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:45:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# sv = svm.SVC()\n",
    "# ab = AdaBoostClassifier(random_state = 1)\n",
    "# gb = GradientBoostingClassifier(random_state = 1)\n",
    "xgb = xgboost.XGBClassifier(random_state = 1)\n",
    "# tree = DecisionTreeClassifier()\n",
    "# nb = MultinomialNB()\n",
    "\n",
    "\n",
    "# Fit and evaluate models\n",
    "results = {}\n",
    "# for cls in [sv, ab, gb, xgb, tree, nb]:\n",
    "for cls in [xgb]:\n",
    "    cls_name = cls.__class__.__name__\n",
    "    results[cls_name] = {}\n",
    "    results[cls_name] = fit_eval_model(cls_name,cls, train_features, y_train, test_features, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcff1a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier\n",
      "\n",
      "train_time :\n",
      "35.16069579124451\n",
      "\n",
      "classification_report :\n",
      "                                          precision    recall  f1-score   support\n",
      "\n",
      "    Acute climatological event (cyclone)       0.68      0.53      0.60       188\n",
      "   Acute climatological event (droughts)       0.60      0.65      0.62       344\n",
      "      Acute climatological event (flood)       0.71      0.68      0.69       231\n",
      "Acute climatological event (heat stress)       0.56      0.30      0.39       114\n",
      "                         Economic Crisis       0.57      0.66      0.61       189\n",
      "                       Man-Made Disaster       0.80      0.79      0.80       160\n",
      "                      Military Conflicts       0.66      0.68      0.67       210\n",
      "                               Terrorism       0.92      0.90      0.91       199\n",
      "                           Trade Dispute       0.66      0.65      0.65       167\n",
      "                             cyberattack       0.95      0.92      0.94       256\n",
      "                       geophysical event       0.81      0.64      0.72       225\n",
      "                           idiosyncratic       0.54      0.73      0.62       282\n",
      "                                pandemic       0.79      0.81      0.80       180\n",
      "\n",
      "                                accuracy                           0.70      2745\n",
      "                               macro avg       0.71      0.69      0.69      2745\n",
      "                            weighted avg       0.71      0.70      0.70      2745\n",
      "\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print (res)\n",
    "    print()\n",
    "    for i in results[res]:\n",
    "        print (i, ':')\n",
    "        print(results[res][i])\n",
    "        print()\n",
    "    print ('-----')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a988ccea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(\"XGBClassifier.sav\", 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab896c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
